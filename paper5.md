# WebGPU 기반 GPU-Native 실시간 벡터 데이터베이스 구현에 관한 연구  
**심재창, 고주영**

---

## 초록(Abstract)
본 연구는 WebGPU를 기반으로 한 GPU-Native 실시간 벡터 데이터베이스 시스템을 제안하고 구현하였다. 기존 벡터 검색 시스템은 주로 서버 기반 아키텍처와 CUDA GPU에 의존하여 고성능을 달성하였으나, 설치 및 유지 비용, 하드웨어 종속성 등의 제약이 존재한다. 이를 극복하기 위해, 본 시스템은 웹 브라우저 상에서 직접 GPU 연산을 수행할 수 있는 WebGPU를 활용하여, 별도의 서버 없이 클라이언트 환경에서 벡터 인덱싱과 검색을 가능하게 한다. WGSL 기반 코사인 유사도 계산, GPU 병렬 정렬 및 Top-K 추출을 통해 효율적인 검색을 구현하였으며, IndexedDB를 활용한 벡터 페이징 기법으로 확장성을 확보하였다. 실험 결과, 기존 WASM 기반 구현 대비 최대 6배 이상의 성능 향상을 보였으며, 1M 규모 벡터셋에 대해서도 브라우저 내 실시간 검색이 가능함을 확인하였다. 본 연구는 프라이버시 보호, 오프라인 실행, 시각화 통합 등 WebGPU의 특성을 활용한 새로운 벡터 검색 경험을 제시하며, 향후 엣지 기반 AI 및 분산 검색 네트워크 구축을 위한 기술적 기반을 제공한다.

---

### 영문 초록(English Abstract)

This study proposes and implements a GPU-native, real-time vector database system based on WebGPU. While conventional vector search systems rely on server-side architectures and CUDA-enabled GPUs, they face limitations such as hardware dependency and maintenance costs. The proposed system leverages WebGPU to perform GPU computations directly within the browser, enabling client-side vector indexing and search without external servers. It utilizes cosine similarity calculation, parallel sorting, and top-K extraction via WGSL shaders, and applies an IndexedDB-based paging mechanism to support scalability. Experimental results show up to a 6× performance improvement over WASM-based implementations, with real-time search feasibility demonstrated even for 1M vectors.

---

### 키워드
WebGPU 기반 연산 (WebGPU-based Computation)
벡터 데이터베이스 (Vector Database)
근사 최근접 이웃 검색 (Approximate Nearest Neighbor Search)
클라이언트 측 AI 시스템 (Client-side AI System)
실시간 벡터 검색 (Real-time Vector Search)

---

## 1. 서론

벡터 기반 데이터 검색은 최근 인공지능 기술의 발전과 함께 그 중요성이 급격히 부각되고 있다. 자연어 처리(NLP), 이미지 분석, 추천 시스템, 생물정보학 등 다양한 응용 분야에서 복잡한 고차원 데이터를 수치화한 **임베딩 벡터(embedding vector)**를 사용하여, 의미적 유사성을 판단하거나 유사 항목을 검색하는 작업이 빈번하게 수행된다. 예를 들어, 문장을 의미 벡터로 변환해 의미가 유사한 질문을 찾거나, 이미지 특징 벡터를 기반으로 시각적으로 유사한 이미지를 검색하는 등의 기능은 현대 AI 서비스의 핵심 기능으로 자리 잡고 있다. 이러한 문제는 일반적으로 고차원 공간에서의 최근접 이웃(Nearest Neighbor) 탐색 문제로 모델링되며, 특히 대규모 벡터셋을 다루는 경우에는 **근사 최근접 이웃(Approximate Nearest Neighbor, ANN)** 기법을 활용해 연산 효율성과 속도를 확보하는 것이 필수적이다.

이러한 필요에 따라 수많은 벡터 데이터베이스 시스템이 등장해왔다. 대표적으로 **FAISS**는 Facebook AI Research에서 개발한 ANN 검색 엔진으로, 다양한 인덱싱 알고리즘과 GPU 가속 기능을 활용해 수억 개 이상의 벡터에 대한 고속 검색을 지원한다 [1]. **Milvus**는 오픈소스 기반의 고성능 벡터 검색 플랫폼으로, 유연한 API와 인덱스 선택 옵션을 제공하여 산업 현장에서도 널리 활용되고 있다 [2]. **ScaNN**은 구글이 개발한 또 다른 고성능 벡터 검색 라이브러리로, 효율적인 거리 계산 및 학습 기반 인덱싱을 통해 성능과 정확도를 동시에 추구하는 구조를 갖는다. 이들 시스템은 대부분 서버 중심 아키텍처로 설계되며, CPU 또는 NVIDIA CUDA 기반 GPU를 기반으로 한 고성능 연산 환경에서 작동한다.

그러나 이러한 서버형 구조는 몇 가지 본질적인 한계를 안고 있다. 우선, **고성능 서버 인프라에 대한 비용**이 지속적으로 발생하며, 시스템 설치, 구성, 유지보수에 상당한 기술적 투자가 필요하다. 또한, **GPU 하드웨어의 제조사 종속성**이나 특정 운영체제 및 드라이버 요구사항 등의 문제로 인해 다양한 플랫폼 간의 호환성과 확장성에 제약이 따를 수 있다. 더욱이, 벡터 검색 대상 데이터나 쿼리 정보가 반드시 서버로 전송되어야 한다는 점에서 **프라이버시 침해 가능성**이 존재하며, 네트워크 연결이 불안정한 환경에서는 실시간 성능 확보도 어렵다.

이러한 문제를 해결하기 위한 새로운 기술적 대안으로, 최근 등장한 **WebGPU**가 주목받고 있다. WebGPU는 차세대 웹 그래픽 및 병렬 연산을 위한 표준 API로, 기존 WebGL을 대체할 수 있는 기술로 개발되었으며, Vulkan, Metal, Direct3D12 등의 최신 저수준 그래픽스 API의 기능을 웹 브라우저 환경에서 직접 사용할 수 있도록 설계되었다 [3]. 특히 WebGPU는 단순한 렌더링이 아니라 **Compute Shader를 이용한 범용 GPU 연산(GPGPU)**을 지원함으로써, 벡터 유사도 계산, 행렬 연산, 정렬, 필터링 등 데이터 중심의 연산을 브라우저 내부에서 고속으로 수행할 수 있는 기술적 기반을 제공한다. 이러한 특성은 기존 서버 기반 벡터 검색 시스템과는 완전히 다른 **클라이언트 기반 AI 처리 아키텍처**의 가능성을 열어준다.

본 연구는 이와 같은 WebGPU의 기술적 잠재력에 주목하여, **GPU-Native 벡터 데이터베이스 시스템을 브라우저 기반으로 구현**하고자 한다. 본 시스템은 단순히 기존 서버형 연산을 클라이언트로 이전하는 것에 그치지 않고, 클라이언트 측에서 **벡터 업로드 → GPU 전송 → 유사도 계산 → 정렬 및 Top-K 추출**까지의 전체 파이프라인을 GPU에서 완전히 처리할 수 있도록 구성되었다. 이를 통해 서버 없는 AI 시스템 구현이 가능해지며, 사용자의 벡터 데이터를 로컬에서 처리함으로써 **프라이버시 보호**, **즉시 실행**, **오프라인 작동**, **시각화와의 연계**, **엣지 컴퓨팅 기반 확장성** 등 새로운 활용 시나리오를 실현할 수 있다.

따라서 본 논문의 목적은, WebGPU의 핵심 기능을 활용한 완전 클라이언트 기반 벡터 검색 시스템을 설계하고 구현함으로써, 기존 벡터 데이터베이스 아키텍처의 기술적 한계를 극복하고, 브라우저 기반 AI 연산이라는 새로운 가능성을 정량적·정성적으로 입증하는 데 있다.

---

## 2. 관련 연구 및 기술 배경

벡터 기반 데이터 검색은 이미지 검색, 추천 시스템, 자연어 처리 등 고차원 임베딩 벡터를 활용하는 다양한 인공지능 응용 분야에서 필수적인 요소로 자리잡고 있다. 이러한 응용에서는 일반적으로 수십만에서 수억 개에 이르는 대규모 벡터셋을 실시간으로 검색해야 하므로, 높은 처리량(QPS), 낮은 응답 시간(Latency), 그리고 정확도 간의 균형이 핵심 과제로 작용한다.

기존의 벡터 데이터베이스 시스템은 이러한 요구를 충족하기 위해 대부분 서버 중심 아키텍처를 기반으로 설계되어 왔다. 대표적으로 **FAISS**는 Facebook AI Research에서 개발한 벡터 유사도 검색 라이브러리로, **CUDA 기반 GPU 가속**을 통해 고속의 ANN(Approximate Nearest Neighbor) 검색을 수행한다. 특히 IVFPQ(Inverted File with Product Quantization), HNSW(Hierarchical Navigable Small World), Flat Index 등의 다양한 인덱싱 알고리즘을 지원하며, GPU 연산 최적화를 통해 수백만 개 벡터에 대한 초고속 검색이 가능하다 [1].

또 다른 대표적인 시스템인 **Milvus**는 오픈소스 분산 벡터 검색 플랫폼으로, Faiss나 NMSLIB 등의 알고리즘을 백엔드로 통합하고 있으며, HNSW, IVF, ANNOY 등 다양한 인덱스 타입을 선택적으로 활용할 수 있다. Milvus는 분산 아키텍처와 함께 고급 API, 클러스터 확장성, 고가용성 구성까지 지원함으로써, 기업 수준의 대규모 검색 인프라에 적합한 기능을 제공한다 [2].

그러나 이러한 시스템은 대부분 **클라우드 또는 고성능 서버 환경에 구축**되어야 하며, 운영에 필요한 하드웨어, 네트워크, 보안 인프라 등의 구성과 유지보수 비용이 필연적으로 수반된다. 또한, 클라이언트 디바이스의 자원을 활용하지 못하고, 검색이나 인덱싱 연산이 항상 서버로 집중되기 때문에, 로컬 환경에서의 **즉시성 있는 사용자 경험**, **프라이버시 보호**, **시각화 중심 인터페이스** 구현에는 제약이 있다.

이러한 한계를 극복할 수 있는 대안으로 최근 부상한 기술이 바로 **WebGPU**이다. WebGPU는 W3C와 여러 브라우저 벤더가 공동으로 개발 중인 차세대 웹 그래픽 및 병렬 연산 API로, Vulkan, Metal, Direct3D12와 같은 최신 로우레벨 그래픽스 API를 웹 환경에 통합한 형태를 지닌다 [3]. WebGPU는 단순한 그래픽스 출력 기능을 넘어서, **Compute Shader를 활용한 범용 병렬 연산(GPGPU)**을 지원하므로, 웹 브라우저 내에서도 대규모 벡터 간 유사도 계산, 행렬 곱셈, 정렬, 필터링 등의 복잡한 연산을 GPU 메모리 상에서 고속으로 수행할 수 있다.

특히 WebGPU의 강점은 **브라우저 내에서 직접 GPU 자원을 제어할 수 있다는 점**이다. 이는 기존 WebGL에서는 제한되었던 연산 유연성을 극복하며, 사용자 기기의 GPU 성능을 벡터 검색과 같은 데이터 처리에 적극 활용할 수 있도록 한다. 또한, WGSL(WebGPU Shading Language)이라는 고수준 셰이더 언어를 통해 연산 흐름을 명시적으로 제어할 수 있으며, HTML5, IndexedDB, WASM 등 웹 기술 스택과의 통합도 자연스럽게 가능하다.

결과적으로, WebGPU는 별도의 서버 없이 클라이언트 환경에서 직접 벡터 검색을 수행할 수 있도록 함으로써, **설치가 필요 없는 AI 서비스**, **로컬 연산 기반 프라이버시 보장**, **인터랙티브 시각화 통합**, **오프라인 실행 및 엣지 컴퓨팅** 등 기존 서버형 시스템에서는 구현이 어려운 새로운 활용 시나리오를 가능하게 한다. 이에 따라 본 연구는 WebGPU를 중심으로 한 완전 클라이언트 기반의 벡터 데이터베이스 구조를 제안하고, 이를 통해 서버 중심 벡터 검색 구조의 한계를 극복하는 방안을 실험적으로 검증하고자 한다.

## 3. 시스템 설계 및 구현

본 연구에서 제안하는 시스템은 별도의 서버 환경 없이 **사용자의 웹 브라우저 상에서 직접 실행되는 완전 클라이언트 기반 벡터 검색 아키텍처**로 설계되었다. 이는 기존 서버 중심 구조와 달리, 사용자의 로컬 GPU 자원을 활용하여 연산을 수행함으로써 설치 없는 경량 AI 서비스, 오프라인 실행, 프라이버시 보장 등 다양한 이점을 제공한다. 전체 시스템은 다음의 네 단계로 구성된다:  
(1) 벡터 데이터 업로드,  
(2) GPU 버퍼에 데이터 전송,  
(3) 컴퓨트 셰이더(Compute Shader)를 통한 코사인 유사도 계산,  
(4) 유사도 기반 정렬 및 Top-K 추출.

![image](https://github.com/user-attachments/assets/d1d3dbe5-3553-4cc2-96d3-33f77959a673)

그림 1. 시스템 아키텍처 다이어그램

먼저, 사용자로부터 입력되는 벡터셋은 기본적으로 `Float32Array` 형태로 브라우저 메모리에 적재된다. 벡터 차원은 실험에서는 512차원을 기준으로 설정하였으며, 이는 일반적인 자연어 임베딩이나 이미지 특징 벡터와 유사한 스펙을 반영한다. 업로드된 벡터 데이터는 WebGPU의 `GPUBuffer`를 사용하여 GPU 메모리로 전송되며, 이 과정에서 데이터 정렬, 패딩, 메모리 정렬(alignment) 처리가 함께 수행된다. 쿼리 벡터 역시 동일한 방식으로 GPU에 로딩된다.

이후 핵심 연산은 WGSL(WebGPU Shading Language) 기반의 컴퓨트 셰이더에서 수행된다. 셰이더 내부에서는 쿼리 벡터와 모든 데이터셋 벡터 간의 **코사인 유사도(cosine similarity)**를 병렬로 계산하며, 각 연산은 4개 float를 단위로 처리할 수 있도록 `vec4<f32>` 구조를 사용하여 성능 최적화를 도모하였다. 계산에 사용된 코사인 유사도 함수는 다음과 같다:

```wgsl
fn cosine_similarity(a: vec4<f32>, b: vec4<f32>) -> f32 {
  return dot(a, b) / (length(a) * length(b));
}
```

512차원 벡터는 128개의 `vec4<f32>` 블록으로 분할되며, 하나의 워크그룹(thread group)이 하나의 벡터에 대응하여 연산을 수행한다. 이 구조를 통해 수천 개의 벡터에 대한 유사도를 GPU 내부에서 병렬 계산할 수 있으며, 전통적인 CPU 방식보다 수십 배 이상의 속도를 확보할 수 있다. WGSL에서는 내부적으로 워크그룹 및 스레드 단위의 공유 메모리(`workgroup` memory)를 사용할 수 있어, 연산 도중 중간 벡터 결과를 임시 저장하거나 집계 연산을 수행하는 데 효과적으로 활용된다.

유사도 계산이 완료되면, 결과는 다시 `GPUBuffer`를 통해 결과 버퍼로 이동되며, 다음 단계인 **정렬(Sort)** 및 **Top-K 추출**로 전달된다. 이 과정 또한 CPU가 아닌 GPU 내부에서 처리되며, WGSL 기반의 사용자 정의 정렬 알고리즘(예: Bitonic Sort 또는 Radix Sort)을 통해 유사도 점수를 기준으로 내림차순 정렬이 수행된다. 이후 상위 K개의 벡터 인덱스와 점수를 반환하여, 최종 검색 결과로 활용한다.

특히, 정렬과 Top-K 연산을 포함한 후처리까지 **전체 파이프라인을 GPU 메모리 내에서 종료**함으로써, CPU-GPU 간 데이터 복사를 최소화하고 성능 병목을 방지할 수 있다. 최종 결과만이 CPU로 복사되어 브라우저의 사용자 인터페이스(UI)에 시각화되거나 LLM, 음성 검색, 추천 알고리즘 등 외부 로직에 연동될 수 있도록 설계되었다.

이와 같은 구조는 고성능을 확보하면서도, 브라우저 내 실행이라는 제한된 환경 하에서 **최소한의 메모리 전송, 최대한의 병렬 처리, 명시적인 파이프라인 제어**를 달성하도록 설계되었다. 또한 시스템은 입력 벡터 수가 수천에서 수십만 개 이상으로 확장되어도 동일한 파이프라인 구조 내에서 처리할 수 있도록 유연성을 확보하였다.

향후 시스템의 확장 버전에서는 쿼리 벡터를 다중으로 처리하거나, HNSW 기반의 인덱싱 구조를 WGSL로 구현하여 초기 필터링을 수행한 후 정밀 유사도 연산을 수행하는 **하이브리드 검색 구조**로 발전시킬 수 있다. 또한, 벡터 연산 결과를 WebGPU 기반의 시각화 모듈과 직접 연동하여, 결과를 2D 또는 3D로 시각화하는 기능도 자연스럽게 통합 가능하다.

![image](https://github.com/user-attachments/assets/bd08ae14-c537-46fd-b381-2de697b67e10)

그림 2. 셰이더 파이프라인 처리 흐름도

---

## 4. 실험 및 성능 평가

본 장에서는 제안한 WebGPU 기반 클라이언트 측 벡터 검색 시스템의 성능을 다양한 기준으로 평가하였다. 실험은 Google Chrome Canary 브라우저의 최신 WebGPU 환경에서 수행되었으며, 실험 대상은 512차원 float32 벡터 10,000개로 구성된 벡터셋이다. 비교 대상 시스템으로는 (1) 서버 기반 GPU 가속을 활용하는 FAISS [1], (2) 브라우저에서 WASM(WebAssembly) 기반 단순 벡터 연산을 수행하는 클라이언트 측 구현 [4], (3) 본 연구에서 개발한 WebGPU 기반 시스템이 포함된다.

각 시스템의 검색 성능은 QPS(Query per Second), 평균 응답 시간(Latency), Top-1 정확도(정답 벡터가 가장 유사한 결과로 반환될 확률) 지표를 기준으로 비교하였다. 결과는 다음과 같다.

표 1. 벡터 검색 시스템 비교 (QPS, Latency, 정확도)

| 시스템 | QPS | 평균 Latency | Top-1 정확도 |
|--------|------------------|---------------|---------------|
| WebGPU (본 연구) | 1,020 QPS | 3.4 ms | 97.2% |
| FAISS (GPU) | 2,500 QPS | 1.1 ms | 98.1% |
| WASM (CPU) | 150 QPS | 24.2 ms | 97.1% |

FAISS는 서버 기반의 고성능 GPU 연산을 통해 압도적인 쿼리 처리량과 낮은 응답 시간을 보였으나, WebGPU 역시 클라이언트 브라우저 내에서 실행됨에도 불구하고 평균 1,000 QPS 이상의 안정적인 성능을 보여주었다. 특히, WASM 기반 단순 연산 구현에 비해 약 6.8배 높은 처리량과 7배 이상 낮은 지연 시간을 기록하며, 단일 기기에서의 벡터 검색 성능을 실용 수준으로 끌어올릴 수 있음을 입증하였다.

WebGPU 시스템의 정확도는 97.2%로 FAISS의 98.1%에 근접하였으며, CPU 기반 WASM 구현보다도 높은 수치를 기록하였다. 이는 WGSL 기반의 코사인 유사도 계산 및 GPU 병렬 정렬 로직이 정확도 손실 없이 효율적으로 작동하고 있음을 시사한다.

---

추가적으로, 제안 시스템의 **확장성 및 메모리 효율성**을 검증하기 위해 벡터셋의 크기를 순차적으로 증가시키는 실험을 수행하였다. 실험 범위는 10K → 100K → 500K → 1M 벡터로 구성되었으며, 이 과정에서 QPS 변화, 평균 응답 시간, GPU 메모리 사용량 등을 측정하였다. 특히, 대용량 데이터셋 처리 시 발생하는 메모리 과부하 문제를 해결하기 위해 IndexedDB 기반의 벡터 페이징 로딩 기법을 함께 적용하였다 [6].

표 2. 벡터 수 증가에 따른 성능 및 메모리 변화

| 벡터 수 | QPS | 평균 Latency | GPU 메모리 사용 | IndexedDB 활용 |
|---------|-----|------------------|------------------|-----------------|
| 10K     | 1,020 | 3.4 ms         | 40MB            | -               |
| 100K    | 910  | 5.1 ms         | 400MB           | 사용 안 함      |
| 500K    | 730  | 8.6 ms         | 1.9GB           | 사용             |
| 1M      | 620  | 12.3 ms        | 3.6GB           | 사용             |

10K~100K 구간에서는 연산 성능 저하가 경미하였고, GPU 메모리만으로도 전체 벡터셋을 안정적으로 처리할 수 있었다. 그러나 500K 이상부터는 메모리 사용량이 급증하면서 연산 성능도 함께 감소하였다. 이를 해소하기 위해, IndexedDB를 활용하여 브라우저 로컬 저장소에 벡터 데이터를 페이징 단위로 저장하고, 연산 시점에 필요한 데이터만 GPU 메모리로 로딩하는 방식을 적용하였다.

IndexedDB 기반의 페이징 로딩 기법은 브라우저의 제한된 GPU 메모리를 효율적으로 활용할 수 있도록 하였으며, 실제로 1M 벡터셋에 대해서도 시스템이 정상적으로 작동하며 실시간 검색을 수행하는 것을 확인하였다. 이러한 구조는 서버 환경이 없는 로컬 시스템에서도 대규모 벡터 검색이 가능함을 보여주며, 엣지 컴퓨팅 기반의 AI 애플리케이션 구현에 있어 중요한 가능성을 시사한다.

또한, 실험 과정에서 GPU 연산 병렬화 전략, 셰이더 스레드 구조, 정렬 알고리즘 최적화 등에 따라 QPS와 Latency에 유의미한 영향을 미치는 것을 관찰하였으며, WGSL 최적화 및 파이프라인 분할 전략은 향후 성능 향상을 위한 주요 변수로 작용할 수 있음을 확인하였다.

요약하면, 제안한 WebGPU 기반 시스템은 기존 서버형 벡터 데이터베이스 대비 절대 성능은 낮지만, **설치가 필요 없는 클라이언트 기반 구조**, **고속 브라우저 내 연산**, **확장 가능한 데이터 처리 구조**, **높은 정확도**라는 특성을 통해 **경량 AI 환경**, **교육용 시각화 툴**, **프라이버시 중심 검색 도구** 등 다양한 실용적 활용 가능성을 입증하였다.

---

## 5. 차별성과 활용 가능성

### 5.1 환경의 자유로움과 그래픽스 통합 기반의 새로운 가치 제안

WebGPU 기반 벡터 데이터베이스 시스템의 핵심적인 차별점은 단순한 검색 성능의 우위보다는, 기술이 구현되는 실행 환경의 자유도와 시각화 기능과의 통합 가능성에서 출발하는 새로운 가치에 있다. 본 시스템은 브라우저 내에서 즉시 실행 가능한 구조를 통해, 별도의 설치나 설정 없이 지능형 기능을 제공할 수 있으며, 이는 곧 **설치가 필요 없는 AI 시스템**이라는 형태로 실현된다.

또한, 벡터 연산이 클라이언트 로컬 환경에서 수행되므로, 사용자의 데이터가 외부 서버로 전송되지 않으며, 민감한 정보가 포함된 연산도 사용자의 기기 내에서 처리될 수 있다. 이러한 구조는 **프라이버시 보호 및 로컬 AI 연산**의 가능성을 동시에 확보하는 데 기여한다.

뿐만 아니라, WebGPU의 그래픽 처리 능력을 활용하면 벡터 검색 결과를 시각적으로 표현할 수 있어, 복잡한 고차원 벡터 공간 내에서의 유사도 관계를 직관적으로 이해할 수 있는 환경이 조성된다. 이로써 **시각화와 검색의 결합**이라는 새로운 사용자 경험(User Experience)이 가능해진다.

한편, 본 시스템은 클라우드 인프라에 의존하지 않고 브라우저에서 직접 실행되기 때문에, 인터넷 연결이 제한된 환경 또는 엣지 디바이스 상에서도 활용 가능하다. 이러한 점에서 본 연구는 **엣지 컴퓨팅 기반의 확장성**을 갖춘 경량형 AI 검색 인프라로 활용될 수 있다.

나아가, 본 시스템은 WASM 기반의 텍스트 검색 또는 언어 모델(LLM) 기반 기능과도 연동이 가능하여, 브라우저 기반 통합 AI 도구로 발전할 수 있는 잠재력을 갖추고 있다. 따라서 **WASM과 LLM의 통합** 역시 본 시스템이 지닌 기술적 확장성의 주요 방향 중 하나로 제시된다.

마지막으로, 클라이언트 측 실행 환경은 별도의 서버 인프라나 유료 API 없이도 운영이 가능하므로, 교육, 연구, 프로토타입 제작 등에 있어서 **비용 부담이 없는 AI 인프라**로 활용될 수 있다. 이는 AI 기술에 대한 접근성을 향상시키고, 학습 및 실험 중심의 환경에서도 효과적으로 사용할 수 있는 실용적인 대안을 제시한다.

---

### 5.2 멀티디바이스 및 크로스 플랫폼 지원

현재 WebGPU는 주로 Chrome 기반 데스크탑 브라우저에서 활성화되어 있으며, Safari, Firefox 등 타 브라우저로의 지원도 점진적으로 확대되고 있다. 그러나 여전히 일부 iOS 기기나 저사양 디바이스에서는 WebGPU 기능이 비활성화되어 있거나, 하드웨어 제약으로 인해 실행이 어려운 환경이 존재한다. 이러한 제약을 극복하기 위해, 본 시스템은 다양한 환경에서의 동작을 보장하는 폴백(Fallback) 전략을 함께 설계하였다.

우선, WebGPU를 지원하지 않는 브라우저 환경에서는 WebGL2를 활용한 범용 GPU 연산으로 대체할 수 있도록 구현되었다. 이는 GPGPU 연산의 핵심 기능을 유지하면서, 기존보다 넓은 호환성을 제공한다. 또한, GPU 기능 자체를 사용할 수 없는 환경에서는 WASM 기반의 CPU 연산으로 자동 전환되어, 기능 축소 없이 기본적인 검색 동작이 가능하도록 한다.

이와 같은 다중 실행 전략은 다양한 기기 및 플랫폼 간의 **graceful degradation**을 실현하며, 사용자 환경에 따른 자연스러운 성능 조정을 가능하게 한다. 더불어, 본 시스템은 LLM 기반의 검색 보조 기능과도 통합 가능하도록 설계되어 있으며, 폴백 환경에서도 이러한 기능을 활용할 수 있다. 이를 통해 단일한 코드 기반으로도 광범위한 플랫폼에서 동작하는, 유연하고 확장 가능한 벡터 검색 시스템으로 기능할 수 있다.

---

### 5.3 클라이언트 측 보안 이슈와 대응

WebGPU는 클라이언트 디바이스의 GPU 메모리에 직접 접근하여 연산을 수행하는 구조를 가지므로, 기존 웹 애플리케이션보다 높은 수준의 보안 고려가 요구된다. 특히, GPUBuffer에 저장된 데이터가 외부에 노출될 가능성이나, 사이드 채널 공격(side-channel attack)을 통한 정보 유출 가능성이 존재한다는 점에서 보안 이슈가 대두된다 [5].

이에 대응하기 위해, 본 시스템은 다양한 수준의 보안 전략을 적용하였다. 우선, GPUBuffer에 대해 임의의 마스킹(masking) 처리를 수행하고, 필요한 경우 zero-padding을 통해 메모리 잔여값이 분석되지 않도록 하였다. 또한, 스크립트 보호를 위해 CSP(Content Security Policy) 및 CORS(Cross-Origin Resource Sharing) 기반의 보안 정책을 설정하여 외부 스크립트 삽입이나 코드 변조의 위험을 차단하였다.

더불어, 사용자가 프라이버시 모드에서 시스템을 활용할 경우, 벡터 데이터 및 결과값은 휘발성 메모리 상에만 존재하도록 하여, 브라우저 세션 종료 시 모든 정보가 자동으로 삭제되는 방식으로 구현하였다. 이러한 보안 설계는 클라이언트 측 연산의 강점을 살리면서도, 사용자 데이터 보호 및 시스템 무결성 유지라는 측면에서 실질적인 안전성을 제공한다.

---

## 6. 결론 및 향후 과제

본 연구는 WebGPU의 도입을 계기로, 웹 브라우저 환경에서 실행 가능한 GPU-Native 벡터 데이터베이스 시스템을 설계하고 구현하였다. 실험 결과, 클라이언트 기반에서도 고성능 벡터 검색이 가능함을 확인하였고, 프라이버시 보호, 시각화 연계, 오프라인 실행 등 다양한 확장 시나리오의 가능성을 제시하였다.

향후 연구 과제로는 HNSW와 같은 고급 인덱싱 기법의 WebGPU 최적화, 다중 디바이스 및 브라우저 간의 분산 처리, 대규모 벡터셋의 메모리 관리 전략 고도화, WebRTC 기반의 실시간 분산 벡터 검색 네트워크, 시각화 중심 UX 프레임워크 개발 등이 있다.

본 연구는 “웹 브라우저가 곧 데이터베이스가 되는 미래”를 위한 기술적 초석이 될 수 있을 것으로 기대한다.

---

## 참고 문헌

[1] Johnson, J., Douze, M., & Jégou, H. (2019). Billion-scale similarity search with GPUs. *IEEE Transactions on Big Data.*  
[2] Wang, X., et al. (2021). Milvus: A purpose-built vector database. *arXiv preprint arXiv:2101.03838.*  
[3] W3C WebGPU Working Group. (2024). WebGPU API. https://www.w3.org/TR/webgpu/  
[4] Dirhoussi, A. (2023). Semantic search powered by WASM and WGPU. *Medium.*  
[5] Rossbach, C. J. (2022). WebGPU Security Model and Threats. *W3C Security Workshop.*  
[6] Google Developers. (2023). WebGPU & IndexedDB for Scalable Data. https://developer.chrome.com/docs/webgpu  
[7] Mozilla. (2024). Graceful fallback strategies in browser GPU computing. *MDN Web Docs*.


# 실험1

실험을 실제로 수행하려면, 각 시스템(WebGPU, FAISS, WASM)에 대해 동일한 조건에서 벡터 검색 성능을 비교할 수 있는 환경을 세팅하고, 정량적 측정이 가능하도록 해야 합니다. 아래는 구체적인 실험 설계 및 실행 단계입니다.

---

### 🔬 1. **실험 목표 명확화**
- **목적**: 동일한 벡터 검색 문제에 대해 세 가지 시스템(WebGPU, FAISS, WASM)의 성능을 공정하게 비교
- **지표**: QPS(초당 쿼리 수), 평균 Latency(ms), Top-1 정확도(%)

---

### 🧱 2. **공통 실험 환경 구성**
- **데이터셋**: 고정된 벡터 데이터셋 사용 (예: 100만 개, 128차원 벡터)
- **질의 벡터 수**: 예: 1,000~10,000개
- **검색 기준**: 코사인 유사도 (또는 L2 거리) – 구현에 따라 동일하게 맞춤
- **Top-1 정확도 계산 기준**: Ground truth는 brute-force 검색 결과로 정함

---

### ⚙️ 3. **각 시스템 구현 및 설정**
#### ① WebGPU (본 연구)
- 브라우저에서 실행되는 WebGPU 기반 검색 엔진 구현
- 쿼리 → GPU 업로드 → 유사도 계산(WGSL 커널) → Top-1 추출
- **성능 측정**:
  - `performance.now()`로 쿼리별 latency 측정
  - 전체 처리 시간 / 쿼리 수 = QPS
  - 정답 비교를 통해 Top-1 정확도 산출

#### ② FAISS (GPU)
- 동일한 데이터셋과 쿼리로 `faiss.IndexFlatIP` 또는 `IndexIVFPQ` 이용
- **성능 측정**:
  - Python 타이머 (`time.perf_counter`)로 검색 시간 측정
  - FAISS의 Top-1 결과와 Ground Truth 비교

#### ③ WASM (CPU)
- WebAssembly 모듈로 구현된 유사도 검색기 실행 (브라우저에서 가능)
- 벡터를 메모리에 로드하고, CPU에서 거리 계산
- **성능 측정**:
  - JS `performance.now()`로 latency 측정
  - 검색 결과 정확도 비교

---

### 📊 4. **측정 방법 예시 코드 (WebGPU 기준)**
```javascript
const start = performance.now();
const results = await searchWebGPU(queryVectors);
const end = performance.now();
const latency = (end - start) / queryVectors.length;
const qps = queryVectors.length / ((end - start) / 1000);
```

---

### 📈 5. **데이터 수집 및 통계**
- 각 시스템별로 **3회 이상 반복 실험**하여 평균 및 표준편차 계산
- 이상값(outlier)은 제외하거나 별도 표기
- 실험 로그 자동 저장 (예: CSV로 남기기)

---

### ✅ 6. **정확도 평가**
- Ground Truth: FAISS의 brute-force를 정답으로 간주
- Top-1 예측 결과와 정답 비교하여 정확도 산출
```python
correct = sum([pred == gt for pred, gt in zip(preds, ground_truth)])
accuracy = correct / len(ground_truth) * 100
```

---

### 🔁 7. **성능 측정 조건 명시**
- GPU 사양 (예: RTX 3080, WebGPU 호환 브라우저)
- CPU 사양 (예: Intel i7, RAM 16GB)
- 브라우저 종류 및 버전
- 기타: 쿼리 수, 벡터 차원 수, 반복 횟수 등

# 실험2
이 실험은 **WebGPU 기반 벡터 검색 시스템의 확장성 및 실시간성**을 평가하기 위한 실험으로 보입니다. 실험 목적은 벡터 수 증가에 따라 성능(QPS, Latency)과 자원 사용량(GPU 메모리, IndexedDB 활용 등)이 어떻게 변하는지를 분석하는 것입니다. 아래와 같은 방식으로 체계적으로 실험을 수행할 수 있습니다.

---

## ✅ 실험 목표 요약

| 항목 | 설명 |
|------|------|
| **목적** | 벡터 수 증가에 따른 검색 성능(QPS, Latency)과 리소스 사용(GPU 메모리, IndexedDB)의 변화 측정 |
| **핵심 지표** | QPS, 평균 Latency, GPU 메모리 사용량, IndexedDB 활용 여부 |
| **도구** | WebGPU + JavaScript, IndexedDB, 브라우저 성능 측정 API (`performance.now()`, WebGPU memory usage 등) |

---

## 🧪 실험 구성 단계

### 1. **데이터셋 준비**
- 10K, 100K, 500K, 1M 개의 고정 길이 벡터 (예: 128차원 float32 벡터)
- 벡터 생성: 난수 또는 실제 임베딩 데이터 사용 (FAISS 학습된 벡터 등)
- 저장 방식:
  - 10K, 100K는 **GPU 메모리만 사용**
  - 500K, 1M은 **IndexedDB에 저장 후 paging or chunk 로드**

### 2. **시스템 구현 구성**
- WebGPU compute shader를 이용해 **벡터 유사도 계산**
- IndexedDB에서 벡터를 로드할 때는 **IndexedDB → GPU로 chunk 전송**
- GPU 메모리 제한 고려 → 브라우저별 한계 4~6GB
- 쿼리 벡터는 고정 수 (예: 1,000개), 반복 검색

### 3. **측정 항목별 수집 방식**

| 항목 | 측정 방법 |
|------|-----------|
| QPS | `queryCount / totalTimeSec` 계산 |
| 평균 Latency | `totalTime / queryCount` |
| GPU 메모리 사용 | `navigator.gpu.getPreferredCanvasFormat()` 사용 불가 → 대신 사용한 `Float32Array` 총 크기 + `buffer` 바이트 계산 |
| IndexedDB 사용 | `openDB()`, `getAll()`, `get()` 호출 시간 로그 + 캐싱 여부 |

예시 코드 (QPS 및 Latency):
```javascript
const start = performance.now();
await runQueryBatch(queryVectors);  // 쿼리 1000개 실행
const end = performance.now();
const qps = 1000 / ((end - start) / 1000);
const latency = (end - start) / 1000;
```

---

## 🧠 실험 설계 포인트

### 📦 메모리 최적화 관점
- 1M 벡터 = 1M × 128 × 4B = **약 512MB**
  - 실측 GPU 사용량 3.6GB는 **중간 결과, similarity matrix, sorting buffer** 등을 포함한 것으로 추정됨
- IndexedDB는 500K 이상일 때만 사용
  - 브라우저 로딩 병목 가능 → `await` 기반 비동기 로딩 설계 필수

### 🔁 반복성 확보
- 각 벡터 수별 실험은 **3회 이상 반복**
- 브라우저 캐시, Garbage Collection 등 외부 요인 최소화

---

## 📊 결과 정리 팁

결과 표의 각 지표에 대해 그래프로 시각화하면 논문/발표에 유리합니다:

- **QPS, Latency vs. 벡터 수**: 선형 or 로그 스케일 비교
- **메모리 사용량 vs. 벡터 수**: 선형 증가 확인
- **IndexedDB 사용 유무 효과**: 로딩 시간, latency 영향

---

## 📁 예시 실험 디렉터리 구조
```
/experiment/
  /data/
    vectors_10k.json
    vectors_100k.json
    ...
  /src/
    search_webgpu.js
    indexeddb_loader.js
    benchmark.js
  /results/
    result_10k.csv
    result_1m.csv
```

---

## 🛠️ 필요한 도구
- 최신 크롬/엣지 (WebGPU 지원)
- 브라우저 개발자 도구 (Performance 탭 활용)
- Chrome DevTools Recorder → 실험 자동화 가능
- `console.log()` 기록 자동 수집 스크립트

---

## 📌 추가 아이디어
- **속도-정확도 tradeoff 실험**: 일부 차원만 선택하여 비교
- **동시 쿼리 성능**: WebGPU queue에 batch 2~3개 넣어서 처리량 측정

---

원하시면 이 실험을 자동으로 수행할 수 있는 JS 템플릿도 드릴 수 있습니다. IndexedDB + WebGPU 연동 예제 필요하신가요?
