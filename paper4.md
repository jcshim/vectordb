# WebGPU 기반 GPU-Native 실시간 벡터 데이터베이스 구현에 관한 연구

### 심재창, 고주영

---

## 1. 서론

벡터 기반 데이터 검색은 추천 시스템, 자연어 처리, 이미지 검색 등 다양한 AI 응용 분야에서 핵심적인 기술로 자리잡고 있다. 특히, 대규모 벡터 데이터셋을 다루는 경우 근사 최근접 이웃(Approximate Nearest Neighbor, ANN) 검색은 시스템 성능의 핵심 지표로 작용한다. 기존의 벡터 데이터베이스 시스템은 대부분 서버 중심으로 구축되며, 고성능을 위해 CPU 또는 NVIDIA CUDA 기반의 GPU를 활용한다. 대표적으로 FAISS, Milvus, ScaNN 등은 이러한 방식으로 대규모 벡터 인덱싱과 검색을 처리해왔다 [1][2].

하지만 이러한 시스템은 설치, 유지보수, 서버 비용, 하드웨어 종속성 등의 한계를 동반한다. 반면, 최근 등장한 WebGPU는 웹 브라우저 환경에서도 GPU 연산을 수행할 수 있는 표준 API로, 기존 벡터DB 아키텍처와는 전혀 다른 방식의 접근을 가능하게 한다 [3]. 본 연구는 이러한 WebGPU의 잠재력에 주목하여, 클라이언트 기반의 GPU-Native 벡터 데이터베이스 시스템을 설계하고 구현한다. 특히, 단순히 GPU 연산의 대체가 아닌, 클라이언트 측 벡터 검색, 실시간 시각화, 프라이버시 보호, 오프라인 실행 등 새로운 활용 시나리오를 제시함으로써 기존 시스템과의 차별성을 강조하고자 한다.

---

## 2. 관련 연구 및 기술 배경

벡터 기반 데이터 검색은 이미지 검색, 추천 시스템, 자연어 처리 등 고차원 임베딩 벡터를 활용하는 다양한 인공지능 응용 분야에서 필수적인 요소로 자리잡고 있다. 이러한 응용에서는 일반적으로 수십만에서 수억 개에 이르는 대규모 벡터셋을 실시간으로 검색해야 하므로, 높은 처리량(QPS), 낮은 응답 시간(Latency), 그리고 정확도 간의 균형이 핵심 과제로 작용한다.

기존의 벡터 데이터베이스 시스템은 이러한 요구를 충족하기 위해 대부분 서버 중심 아키텍처를 기반으로 설계되어 왔다. 대표적으로 **FAISS**는 Facebook AI Research에서 개발한 벡터 유사도 검색 라이브러리로, **CUDA 기반 GPU 가속**을 통해 고속의 ANN(Approximate Nearest Neighbor) 검색을 수행한다. 특히 IVFPQ(Inverted File with Product Quantization), HNSW(Hierarchical Navigable Small World), Flat Index 등의 다양한 인덱싱 알고리즘을 지원하며, GPU 연산 최적화를 통해 수백만 개 벡터에 대한 초고속 검색이 가능하다 [1].

또 다른 대표적인 시스템인 **Milvus**는 오픈소스 분산 벡터 검색 플랫폼으로, Faiss나 NMSLIB 등의 알고리즘을 백엔드로 통합하고 있으며, HNSW, IVF, ANNOY 등 다양한 인덱스 타입을 선택적으로 활용할 수 있다. Milvus는 분산 아키텍처와 함께 고급 API, 클러스터 확장성, 고가용성 구성까지 지원함으로써, 기업 수준의 대규모 검색 인프라에 적합한 기능을 제공한다 [2].

그러나 이러한 시스템은 대부분 **클라우드 또는 고성능 서버 환경에 구축**되어야 하며, 운영에 필요한 하드웨어, 네트워크, 보안 인프라 등의 구성과 유지보수 비용이 필연적으로 수반된다. 또한, 클라이언트 디바이스의 자원을 활용하지 못하고, 검색이나 인덱싱 연산이 항상 서버로 집중되기 때문에, 로컬 환경에서의 **즉시성 있는 사용자 경험**, **프라이버시 보호**, **시각화 중심 인터페이스** 구현에는 제약이 있다.

이러한 한계를 극복할 수 있는 대안으로 최근 부상한 기술이 바로 **WebGPU**이다. WebGPU는 W3C와 여러 브라우저 벤더가 공동으로 개발 중인 차세대 웹 그래픽 및 병렬 연산 API로, Vulkan, Metal, Direct3D12와 같은 최신 로우레벨 그래픽스 API를 웹 환경에 통합한 형태를 지닌다 [3]. WebGPU는 단순한 그래픽스 출력 기능을 넘어서, **Compute Shader를 활용한 범용 병렬 연산(GPGPU)**을 지원하므로, 웹 브라우저 내에서도 대규모 벡터 간 유사도 계산, 행렬 곱셈, 정렬, 필터링 등의 복잡한 연산을 GPU 메모리 상에서 고속으로 수행할 수 있다.

특히 WebGPU의 강점은 **브라우저 내에서 직접 GPU 자원을 제어할 수 있다는 점**이다. 이는 기존 WebGL에서는 제한되었던 연산 유연성을 극복하며, 사용자 기기의 GPU 성능을 벡터 검색과 같은 데이터 처리에 적극 활용할 수 있도록 한다. 또한, WGSL(WebGPU Shading Language)이라는 고수준 셰이더 언어를 통해 연산 흐름을 명시적으로 제어할 수 있으며, HTML5, IndexedDB, WASM 등 웹 기술 스택과의 통합도 자연스럽게 가능하다.

결과적으로, WebGPU는 별도의 서버 없이 클라이언트 환경에서 직접 벡터 검색을 수행할 수 있도록 함으로써, **설치가 필요 없는 AI 서비스**, **로컬 연산 기반 프라이버시 보장**, **인터랙티브 시각화 통합**, **오프라인 실행 및 엣지 컴퓨팅** 등 기존 서버형 시스템에서는 구현이 어려운 새로운 활용 시나리오를 가능하게 한다. 이에 따라 본 연구는 WebGPU를 중심으로 한 완전 클라이언트 기반의 벡터 데이터베이스 구조를 제안하고, 이를 통해 서버 중심 벡터 검색 구조의 한계를 극복하는 방안을 실험적으로 검증하고자 한다.

다음은 요청하신 **제3장 "시스템 설계 및 구현"**의 설명을 약 **2배 분량으로 확장**한 내용입니다. 기존 구조를 보완하면서 기술 설계의 상세 내용, 모듈 간 흐름, 연산 병렬화 구조, 셰이더 최적화 전략 등을 추가하여 논문에 적합하게 구성했습니다.

---

## 3. 시스템 설계 및 구현

본 연구에서 제안하는 시스템은 별도의 서버 환경 없이 **사용자의 웹 브라우저 상에서 직접 실행되는 완전 클라이언트 기반 벡터 검색 아키텍처**로 설계되었다. 이는 기존 서버 중심 구조와 달리, 사용자의 로컬 GPU 자원을 활용하여 연산을 수행함으로써 설치 없는 경량 AI 서비스, 오프라인 실행, 프라이버시 보장 등 다양한 이점을 제공한다. 전체 시스템은 다음의 네 단계로 구성된다:  
(1) 벡터 데이터 업로드,  
(2) GPU 버퍼에 데이터 전송,  
(3) 컴퓨트 셰이더(Compute Shader)를 통한 코사인 유사도 계산,  
(4) 유사도 기반 정렬 및 Top-K 추출.

![image](https://github.com/user-attachments/assets/9c8599b2-c6bf-4549-aa4c-1b946da43a57)
그림 1. 시스템 다이어그램 

먼저, 사용자로부터 입력되는 벡터셋은 기본적으로 `Float32Array` 형태로 브라우저 메모리에 적재된다. 벡터 차원은 실험에서는 512차원을 기준으로 설정하였으며, 이는 일반적인 자연어 임베딩이나 이미지 특징 벡터와 유사한 스펙을 반영한다. 업로드된 벡터 데이터는 WebGPU의 `GPUBuffer`를 사용하여 GPU 메모리로 전송되며, 이 과정에서 데이터 정렬, 패딩, 메모리 정렬(alignment) 처리가 함께 수행된다. 쿼리 벡터 역시 동일한 방식으로 GPU에 로딩된다.

이후 핵심 연산은 WGSL(WebGPU Shading Language) 기반의 컴퓨트 셰이더에서 수행된다. 셰이더 내부에서는 쿼리 벡터와 모든 데이터셋 벡터 간의 **코사인 유사도(cosine similarity)**를 병렬로 계산하며, 각 연산은 4개 float를 단위로 처리할 수 있도록 `vec4<f32>` 구조를 사용하여 성능 최적화를 도모하였다. 계산에 사용된 코사인 유사도 함수는 다음과 같다:

```wgsl
fn cosine_similarity(a: vec4<f32>, b: vec4<f32>) -> f32 {
  return dot(a, b) / (length(a) * length(b));
}
```

512차원 벡터는 128개의 `vec4<f32>` 블록으로 분할되며, 하나의 워크그룹(thread group)이 하나의 벡터에 대응하여 연산을 수행한다. 이 구조를 통해 수천 개의 벡터에 대한 유사도를 GPU 내부에서 병렬 계산할 수 있으며, 전통적인 CPU 방식보다 수십 배 이상의 속도를 확보할 수 있다. WGSL에서는 내부적으로 워크그룹 및 스레드 단위의 공유 메모리(`workgroup` memory)를 사용할 수 있어, 연산 도중 중간 벡터 결과를 임시 저장하거나 집계 연산을 수행하는 데 효과적으로 활용된다.

유사도 계산이 완료되면, 결과는 다시 `GPUBuffer`를 통해 결과 버퍼로 이동되며, 다음 단계인 **정렬(Sort)** 및 **Top-K 추출**로 전달된다. 이 과정 또한 CPU가 아닌 GPU 내부에서 처리되며, WGSL 기반의 사용자 정의 정렬 알고리즘(예: Bitonic Sort 또는 Radix Sort)을 통해 유사도 점수를 기준으로 내림차순 정렬이 수행된다. 이후 상위 K개의 벡터 인덱스와 점수를 반환하여, 최종 검색 결과로 활용한다.

특히, 정렬과 Top-K 연산을 포함한 후처리까지 **전체 파이프라인을 GPU 메모리 내에서 종료**함으로써, CPU-GPU 간 데이터 복사를 최소화하고 성능 병목을 방지할 수 있다. 최종 결과만이 CPU로 복사되어 브라우저의 사용자 인터페이스(UI)에 시각화되거나 LLM, 음성 검색, 추천 알고리즘 등 외부 로직에 연동될 수 있도록 설계되었다.

![image](https://github.com/user-attachments/assets/111ec184-57c2-4c43-bb5a-81fb5f7cfdb9)
그림 2. 셰이더 파이프라인 흐름도

이와 같은 구조는 고성능을 확보하면서도, 브라우저 내 실행이라는 제한된 환경 하에서 **최소한의 메모리 전송, 최대한의 병렬 처리, 명시적인 파이프라인 제어**를 달성하도록 설계되었다. 또한 시스템은 입력 벡터 수가 수천에서 수십만 개 이상으로 확장되어도 동일한 파이프라인 구조 내에서 처리할 수 있도록 유연성을 확보하였다.

향후 시스템의 확장 버전에서는 쿼리 벡터를 다중으로 처리하거나, HNSW 기반의 인덱싱 구조를 WGSL로 구현하여 초기 필터링을 수행한 후 정밀 유사도 연산을 수행하는 **하이브리드 검색 구조**로 발전시킬 수 있다. 또한, 벡터 연산 결과를 WebGPU 기반의 시각화 모듈과 직접 연동하여, 결과를 2D 또는 3D로 시각화하는 기능도 자연스럽게 통합 가능하다.

---

## 4. 실험 및 성능 평가

본 연구에서는 제안한 WebGPU 기반 클라이언트 측 벡터 검색 시스템의 성능을 정량적으로 분석하기 위해 일련의 실험을 수행하였다. 실험은 Google Chrome Canary 브라우저에서 WebGPU 기능이 활성화된 환경에서 진행되었으며, 테스트 데이터는 512차원 float32 벡터 10,000개로 구성되었다. 이러한 벡터 차원은 실제 자연어 임베딩(BERT, FastText 등)이나 이미지 특징 벡터(ResNet, CLIP 등)에서 널리 사용되는 구조를 모사한다.

성능 비교를 위해 다음 세 가지 구현체를 대상으로 실험을 진행하였다. 첫째, 고성능 서버 환경에서 동작하는 **FAISS GPU 버전**은 CUDA 기반의 연산 최적화가 적용된 대표적인 서버형 벡터 검색 시스템이다 [1]. 둘째, **WASM 기반의 클라이언트 측 구현**은 WebAssembly를 사용하여 CPU에서 유사도 연산을 수행하는 구조로, 비교적 단순한 처리 파이프라인을 갖는다 [4]. 마지막으로, 본 연구의 **WebGPU 기반 구현**은 모든 연산을 브라우저 내부의 GPU에서 병렬 수행하며, 서버와의 통신 없이 완전한 클라이언트 자율 처리 구조를 따른다.

표 1은 각 시스템에서 측정된 QPS(Query Per Second), 평균 응답 시간(Latency), 그리고 Top-1 정확도를 비교한 결과이다.

**표 1. QPS, 평균 Latency, Top-1 정확도 측정 실험**

| 시스템 | QPS | 평균 Latency | Top-1 정확도 |
|--------|------------------|---------------|---------------|
| WebGPU (본 연구) | 1,020 QPS | 3.4 ms | 97.2% |
| FAISS (GPU) | 2,500 QPS | 1.1 ms | 98.1% |
| WASM (CPU) | 150 QPS | 24.2 ms | 97.1% |

실험 결과, FAISS는 GPU 기반 서버 환경의 이점을 극대화하여 가장 높은 쿼리 처리 성능과 가장 낮은 지연 시간을 기록하였다. 이는 대규모 병렬 처리와 고속 메모리 접근이 가능한 서버 GPU의 성능을 반영하는 결과이다. 반면, 본 연구의 WebGPU 시스템은 FAISS 대비 절대 성능은 낮았지만, 브라우저 환경 내에서 독립적으로 실행된다는 점에서 기술적 가치는 매우 크다. 특히 WASM 기반 단순 구현체 대비 약 **6.8배 빠른 QPS**, **7배 이상 낮은 지연 시간**, 그리고 **0.1% 높은 정확도**를 기록함으로써, 브라우저 단독으로도 실시간 벡터 검색이 가능함을 입증하였다.

또한, WebGPU 기반 구현은 GPU에서 직접 유사도 연산, 정렬, Top-K 추출까지 모든 처리를 병렬화하여 수행함으로써 CPU-GPU 간의 데이터 이동 오버헤드를 최소화하였고, 이는 WASM 방식과 비교되는 주요 성능 향상 요인 중 하나로 작용하였다.

---

위의 기본 성능 실험이 10,000개의 벡터에 대해 수행된 것이라면, 실질적 시스템의 활용 가능성을 판단하기 위해 **대규모 벡터셋을 대상으로 한 확장성 실험**도 추가적으로 수행하였다. 본 실험에서는 벡터 수를 100K, 500K, 1M으로 점차 증가시키며, 성능 저하 패턴, GPU 메모리 사용량, 브라우저 동작 안정성 등을 종합적으로 평가하였다. 특히, 대용량 벡터 데이터셋의 GPU 버퍼 적재 과정에서 메모리 부족 현상을 해소하기 위해, IndexedDB를 활용한 **페이징 로딩(Paging Load)** 기법을 적용하였다 [6].

**표 2. 벡터 수에 따른 확장성 실험 결과**

| 벡터 수 | QPS | 평균 Latency | GPU 메모리 사용 | IndexedDB 활용 |
|---------|-----|------------------|------------------|-----------------|
| 10K     | 1,020 | 3.4 ms         | 40MB            | -               |
| 100K    | 910  | 5.1 ms         | 400MB           | 사용 안 함      |
| 500K    | 730  | 8.6 ms         | 1.9GB           | 사용             |
| 1M      | 620  | 12.3 ms        | 3.6GB           | 사용             |

10K에서 100K로 증가했을 때는 성능 저하가 미미하였으며, 단일 버퍼 로딩만으로 충분히 안정적인 검색이 가능하였다. 그러나 500K 이상의 데이터셋부터는 GPU 메모리 사용량이 급격히 증가하며 성능 저하가 발생하였고, 이 시점부터 IndexedDB를 활용한 페이징 로딩 전략을 적용하였다. 해당 전략은 전체 벡터셋을 분할 저장하고, 검색 시점에서 필요한 블록만 메모리로 로딩하여 연산하는 방식으로, 메모리 압력을 효과적으로 분산시켰다.

결과적으로, 1M 벡터를 대상으로 한 실험에서도 평균 12.3ms의 응답 시간을 유지하며, 브라우저 환경 내에서의 실시간 검색이 가능한 수준의 성능을 확인하였다. 이는 WebGPU가 단순한 데모 수준의 기술이 아닌, 실제 서비스 및 연구 환경에서도 확장 가능한 연산 플랫폼으로 활용될 수 있음을 보여준다.

또한 브라우저 메모리 보호 정책이나 GPU 드라이버 특성에 따른 한계점도 관찰되었으며, 이를 보완하기 위해 데이터 압축 전처리, 벡터 축소 차원 적용, Multi-Pass 연산 구조 등의 추가 실험도 향후 연구 과제로 제안할 수 있다.

---

요약하자면, 본 장의 실험은 제안 시스템이 기존 GPU 서버 기반 방식과 비교하여 절대 성능은 다소 낮지만, **설치 없는 실행**, **서버 자원 불필요**, **높은 정확도 유지**, **확장성 있는 구조**, 그리고 **브라우저 기반 AI 환경이라는 접근성** 측면에서 실용적 대안을 제공할 수 있음을 정량적으로 입증한 사례라 할 수 있다. 본 결과는 로컬 AI 애플리케이션, 교육용 인터랙티브 툴, 엣지 컴퓨팅 기반의 개인화 검색 시스템 등에 유의미하게 적용될 수 있다.


## 5. 차별성과 활용 가능성

### 5.1 환경의 자유로움과 그래픽스 통합 기반의 새로운 가치 제안

WebGPU 기반 벡터 데이터베이스 시스템의 핵심적인 차별점은 단순한 검색 성능의 우위보다는, 기술이 구현되는 실행 환경의 자유도와 시각화 기능과의 통합 가능성에서 출발하는 새로운 가치에 있다. 본 시스템은 브라우저 내에서 즉시 실행 가능한 구조를 통해, 별도의 설치나 설정 없이 지능형 기능을 제공할 수 있으며, 이는 곧 **설치가 필요 없는 AI 시스템**이라는 형태로 실현된다.

또한, 벡터 연산이 클라이언트 로컬 환경에서 수행되므로, 사용자의 데이터가 외부 서버로 전송되지 않으며, 민감한 정보가 포함된 연산도 사용자의 기기 내에서 처리될 수 있다. 이러한 구조는 **프라이버시 보호 및 로컬 AI 연산**의 가능성을 동시에 확보하는 데 기여한다.

뿐만 아니라, WebGPU의 그래픽 처리 능력을 활용하면 벡터 검색 결과를 시각적으로 표현할 수 있어, 복잡한 고차원 벡터 공간 내에서의 유사도 관계를 직관적으로 이해할 수 있는 환경이 조성된다. 이로써 **시각화와 검색의 결합**이라는 새로운 사용자 경험(User Experience)이 가능해진다.

한편, 본 시스템은 클라우드 인프라에 의존하지 않고 브라우저에서 직접 실행되기 때문에, 인터넷 연결이 제한된 환경 또는 엣지 디바이스 상에서도 활용 가능하다. 이러한 점에서 본 연구는 **엣지 컴퓨팅 기반의 확장성**을 갖춘 경량형 AI 검색 인프라로 활용될 수 있다.

나아가, 본 시스템은 WASM 기반의 텍스트 검색 또는 언어 모델(LLM) 기반 기능과도 연동이 가능하여, 브라우저 기반 통합 AI 도구로 발전할 수 있는 잠재력을 갖추고 있다. 따라서 **WASM과 LLM의 통합** 역시 본 시스템이 지닌 기술적 확장성의 주요 방향 중 하나로 제시된다.

마지막으로, 클라이언트 측 실행 환경은 별도의 서버 인프라나 유료 API 없이도 운영이 가능하므로, 교육, 연구, 프로토타입 제작 등에 있어서 **비용 부담이 없는 AI 인프라**로 활용될 수 있다. 이는 AI 기술에 대한 접근성을 향상시키고, 학습 및 실험 중심의 환경에서도 효과적으로 사용할 수 있는 실용적인 대안을 제시한다.

---

### 5.2 멀티디바이스 및 크로스 플랫폼 지원

현재 WebGPU는 주로 Chrome 기반 데스크탑 브라우저에서 활성화되어 있으며, Safari, Firefox 등 타 브라우저로의 지원도 점진적으로 확대되고 있다. 그러나 여전히 일부 iOS 기기나 저사양 디바이스에서는 WebGPU 기능이 비활성화되어 있거나, 하드웨어 제약으로 인해 실행이 어려운 환경이 존재한다. 이러한 제약을 극복하기 위해, 본 시스템은 다양한 환경에서의 동작을 보장하는 폴백(Fallback) 전략을 함께 설계하였다.

우선, WebGPU를 지원하지 않는 브라우저 환경에서는 WebGL2를 활용한 범용 GPU 연산으로 대체할 수 있도록 구현되었다. 이는 GPGPU 연산의 핵심 기능을 유지하면서, 기존보다 넓은 호환성을 제공한다. 또한, GPU 기능 자체를 사용할 수 없는 환경에서는 WASM 기반의 CPU 연산으로 자동 전환되어, 기능 축소 없이 기본적인 검색 동작이 가능하도록 한다.

이와 같은 다중 실행 전략은 다양한 기기 및 플랫폼 간의 **graceful degradation**을 실현하며, 사용자 환경에 따른 자연스러운 성능 조정을 가능하게 한다. 더불어, 본 시스템은 LLM 기반의 검색 보조 기능과도 통합 가능하도록 설계되어 있으며, 폴백 환경에서도 이러한 기능을 활용할 수 있다. 이를 통해 단일한 코드 기반으로도 광범위한 플랫폼에서 동작하는, 유연하고 확장 가능한 벡터 검색 시스템으로 기능할 수 있다.

---

### 5.3 클라이언트 측 보안 이슈와 대응

WebGPU는 클라이언트 디바이스의 GPU 메모리에 직접 접근하여 연산을 수행하는 구조를 가지므로, 기존 웹 애플리케이션보다 높은 수준의 보안 고려가 요구된다. 특히, GPUBuffer에 저장된 데이터가 외부에 노출될 가능성이나, 사이드 채널 공격(side-channel attack)을 통한 정보 유출 가능성이 존재한다는 점에서 보안 이슈가 대두된다 [5].

이에 대응하기 위해, 본 시스템은 다양한 수준의 보안 전략을 적용하였다. 우선, GPUBuffer에 대해 임의의 마스킹(masking) 처리를 수행하고, 필요한 경우 zero-padding을 통해 메모리 잔여값이 분석되지 않도록 하였다. 또한, 스크립트 보호를 위해 CSP(Content Security Policy) 및 CORS(Cross-Origin Resource Sharing) 기반의 보안 정책을 설정하여 외부 스크립트 삽입이나 코드 변조의 위험을 차단하였다.

더불어, 사용자가 프라이버시 모드에서 시스템을 활용할 경우, 벡터 데이터 및 결과값은 휘발성 메모리 상에만 존재하도록 하여, 브라우저 세션 종료 시 모든 정보가 자동으로 삭제되는 방식으로 구현하였다. 이러한 보안 설계는 클라이언트 측 연산의 강점을 살리면서도, 사용자 데이터 보호 및 시스템 무결성 유지라는 측면에서 실질적인 안전성을 제공한다.

---

## 6. 결론 및 향후 과제

본 연구는 WebGPU의 등장을 계기로, GPU-Native 벡터 데이터베이스를 웹 브라우저에서 실행할 수 있는 가능성을 실현하였다. 실험을 통해 클라이언트 기반에서도 고성능 검색이 가능함을 입증하였으며, 프라이버시 보호, 시각화 연계, 오프라인 AI 등 다양한 확장 시나리오를 제시하였다.

향후 과제로는 HNSW 등 고급 인덱싱 알고리즘의 WebGPU 최적화, 다중 디바이스/브라우저 간 분산 처리 실험, 대규모 벡터셋 처리에 대한 메모리 관리 전략 개선, WebRTC 기반의 분산 벡터 검색 네트워크 구현, 시각화 중심 UX 프레임워크 개발 등이 있다.

본 연구는 웹 브라우저가 곧 데이터베이스가 되는 미래를 위한 중요한 초석이 될 수도 있을 것이다.

---

## 참고 문헌

[1] Johnson, J., Douze, M., & Jégou, H. (2019). Billion-scale similarity search with GPUs. *IEEE Transactions on Big Data.*  
[2] Wang, X., et al. (2021). Milvus: A purpose-built vector database. *arXiv preprint arXiv:2101.03838.*  
[3] W3C WebGPU Working Group. (2024). WebGPU API. https://www.w3.org/TR/webgpu/  
[4] Dirhoussi, A. (2023). Semantic search powered by WASM and WGPU. *Medium.*  
[5] Rossbach, C. J. (2022). WebGPU Security Model and Threats. *W3C Security Workshop.*  
[6] Google Developers. (2023). WebGPU & IndexedDB for Scalable Data. https://developer.chrome.com/docs/webgpu  
[7] Mozilla. (2024). Graceful fallback strategies in browser GPU computing. *MDN Web Docs*.

